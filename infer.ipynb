{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaivi2028/Get-Set-Git-Online/blob/main/infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-hxUjf6XahL",
        "outputId": "2db31758-9d9c-43c1-e5e6-cc1bdbb6e838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfYoKXr6rxi",
        "outputId": "5e71fa8d-c700-4ad4-b2b7-a04cc94b2179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar 10 06:01:56 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz21kFuwCvNW"
      },
      "source": [
        "## download github files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5SN8GRf7m6s",
        "outputId": "5ea95115-ac07-46db-edbb-99717fd04e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HeadSwap' already exists and is not an empty directory.\n",
            "/content/HeadSwap/process\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/LeslieZhoa/HeadSwap.git\n",
        "%cd HeadSwap/process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule sync --recursive #Ensure submodule URLs are up-to-date\n",
        "!git submodule update --init --recursive --remote #Initialize, fetch, and checkout submodules"
      ],
      "metadata": {
        "id": "aNAoLwM5o6Rz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXYkmmu-C9zV"
      },
      "source": [
        "## download model path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_BOlr58Fe8",
        "outputId": "47be9aa5-58f6-4eb8-d78f-f010e55d3411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-10 06:02:11--  https://github.com/LeslieZhoa/HeSer.Pytorch/releases/download/v0.0/parsing.pth\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250310T060211Z&X-Amz-Expires=300&X-Amz-Signature=49ae8b40db671b4fecfd05b215bb0eec809ab70d02af8433d84f57063fd74005&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-10 06:02:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/530152897/e4c87da5-2ba5-43b4-a5d5-24270c4a925c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250310T060211Z&X-Amz-Expires=300&X-Amz-Signature=49ae8b40db671b4fecfd05b215bb0eec809ab70d02af8433d84f57063fd74005&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dparsing.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53289463 (51M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/parsing.pth.4’\n",
            "\n",
            "parsing.pth.4       100%[===================>]  50.82M   271MB/s    in 0.2s    \n",
            "\n",
            "2025-03-10 06:02:11 (271 MB/s) - ‘../pretrained_models/parsing.pth.4’ saved [53289463/53289463]\n",
            "\n",
            "--2025-03-10 06:02:11--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/sr_cf.onnx\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250310T060212Z&X-Amz-Expires=300&X-Amz-Signature=2ec5dc8714e635e87a0469242fc06b8451fe36de83e5ab27eb810af918d52464&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-10 06:02:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/ceed01af-bdaa-4a77-8599-f41da0a9cebf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250310T060212Z&X-Amz-Expires=300&X-Amz-Signature=2ec5dc8714e635e87a0469242fc06b8451fe36de83e5ab27eb810af918d52464&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dsr_cf.onnx&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 376642743 (359M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/sr_cf.onnx.4’\n",
            "\n",
            "sr_cf.onnx.4        100%[===================>] 359.19M   275MB/s    in 1.3s    \n",
            "\n",
            "2025-03-10 06:02:13 (275 MB/s) - ‘../pretrained_models/sr_cf.onnx.4’ saved [376642743/376642743]\n",
            "\n",
            "--2025-03-10 06:02:13--  https://github.com/LeslieZhoa/HeadSwap/releases/download/v0.0/Blender-401-00012900.pth\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250310T060213Z&X-Amz-Expires=300&X-Amz-Signature=7aef178fceb2cf5ea73b4e9c34acbfaa88d203ba2543feafe8c45d8edfe57b54&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-10 06:02:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/580735966/a967bbbb-08bf-440a-86b0-ff59bfea0867?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250310%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250310T060213Z&X-Amz-Expires=300&X-Amz-Signature=7aef178fceb2cf5ea73b4e9c34acbfaa88d203ba2543feafe8c45d8edfe57b54&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DBlender-401-00012900.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 788213979 (752M) [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/Blender-401-00012900.pth.4’\n",
            "\n",
            "Blender-401-0001290 100%[===================>] 751.70M   219MB/s    in 3.4s    \n",
            "\n",
            "2025-03-10 06:02:17 (220 MB/s) - ‘../pretrained_models/Blender-401-00012900.pth.4’ saved [788213979/788213979]\n",
            "\n",
            "--2025-03-10 06:02:17--  https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 994 [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/BFM/similarity_Lm3D_all.mat.4’\n",
            "\n",
            "similarity_Lm3D_all 100%[===================>]     994  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-10 06:02:17 (74.8 MB/s) - ‘../pretrained_models/BFM/similarity_Lm3D_all.mat.4’ saved [994/994]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! bash download_weight.sh\n",
        "! wget https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat -P ../pretrained_models/BFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MGEEwCHZCohn"
      },
      "outputs": [],
      "source": [
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = '../pretrained_models'\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gd0BrM1rDO3a",
        "outputId": "9f4093a6-2f15-4017-f42d-5536e1c4e0d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_20.pth already exists!\n"
          ]
        }
      ],
      "source": [
        "#@title Download epoch_20\n",
        "MODEL_PATHS = {\"id\": \"1BlDBB4dLLrlN3cJhVL4nmrd_g6Jx6uP0\", \"name\": \"epoch_20.pth\"}\n",
        "\n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5drU3CIUEY6"
      },
      "source": [
        "## Download PIRender model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL8N3M_DUD3m",
        "outputId": "5937e7eb-13fb-4aa8-bb38-a0c5f5ba7879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face.zip already exists!\n",
            "/content/HeadSwap/pretrained_models\n",
            "Archive:  face.zip\n",
            "  inflating: face/epoch_00190_iteration_000400000_checkpoint.pt  \n",
            "replace face/latest_checkpoint.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: face/latest_checkpoint.txt  \n"
          ]
        }
      ],
      "source": [
        "MODEL_PATHS = {\"id\": \"1-0xOf6g58OmtKtEWJlU3VlnfRqPN9Uq7\", \"name\": \"face.zip\"}\n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])\n",
        "%cd ../pretrained_models\n",
        "! unzip -x face.zip\n",
        "! mv face/epoch_00190_iteration_000400000_checkpoint.pt ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IM_NnH0YL-V",
        "outputId": "56f5b63a-b64a-44b4-e665-6a8910177ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BFM\t\t\t\t\t       epoch_20.pth   parsing.pth.4\n",
            "Blender-401-00012900.pth\t\t       face\t      sr_cf.onnx\n",
            "Blender-401-00012900.pth.1\t\t       face.zip       sr_cf.onnx.1\n",
            "Blender-401-00012900.pth.2\t\t       parsing.pth    sr_cf.onnx.2\n",
            "Blender-401-00012900.pth.3\t\t       parsing.pth.1  sr_cf.onnx.3\n",
            "Blender-401-00012900.pth.4\t\t       parsing.pth.2  sr_cf.onnx.4\n",
            "epoch_00190_iteration_000400000_checkpoint.pt  parsing.pth.3\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lCGm7VnDc02"
      },
      "source": [
        "## enviroment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzfacabV9Bzq",
        "outputId": "ffe230b1-5e62-45e9-af67-bad85f99f9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HeadSwap\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Collecting torch==1.13.1+cu117 (from -r requirements.txt (line 3))\n",
            "  Using cached https://download.pytorch.org/whl/cu117/torch-1.13.1%2Bcu117-cp311-cp311-linux_x86_64.whl (1801.8 MB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1+cu117 (from versions: 0.1.6, 0.2.0, 0.15.0+cu117, 0.15.1, 0.15.1+cu117, 0.15.2, 0.15.2+cu117, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1+cu117\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%cd /content/HeadSwap\n",
        "! apt install python3.10\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls HeadSwap/model/third/Deep3dRec/"
      ],
      "metadata": {
        "id": "8X2juU5GnqXQ",
        "outputId": "22f554c1-8582-4520-8dce-27a6cfdfb431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'HeadSwap/model/third/Deep3dRec/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-FY1EmBRsoj"
      },
      "source": [
        "Maybe you meet restart warning because of the numpy, just restart it. When starting over, start running from the following section!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ./model/third/Deep3dRec"
      ],
      "metadata": {
        "id": "_cnlAFqnqmms",
        "outputId": "58a320b1-ea88-4f70-eaef-445e4f9a7b83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/HeadSwap/model/third/Deep3dRec\n",
            "\u001b[31mERROR: file:///content/HeadSwap/model/third/Deep3dRec does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/HeadSwap/model/third/Deep3dRec"
      ],
      "metadata": {
        "id": "fKNwQ4iMrMlq",
        "outputId": "e83563c7-1649-4a56-8de2-8069227c8989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HeadSwap/model/third/Deep3dRec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! touch /content/HeadSwap/model/third/Deep3dRec/__init__.py"
      ],
      "metadata": {
        "id": "1kH-iR7Ysa--"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "d1nd1n23-ZET",
        "outputId": "f60ff4f7-076c-4e94-f38b-cecc8c5db5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HeadSwap\n",
            "Requirement already satisfied: face-alignment in /usr/local/lib/python3.11/dist-packages (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from face-alignment) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face-alignment) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.11/dist-packages (from face-alignment) (1.13.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from face-alignment) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from face-alignment) (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from face-alignment) (4.67.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from face-alignment) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->face-alignment) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->face-alignment) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->face-alignment) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->face-alignment) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->face-alignment) (3.0.2)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model.third.Deep3dRec.utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-33926e9657bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_func\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HeadSwap/process/process_func.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeep3dRec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReconNetWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeep3dRec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malign_img\u001b[0m \u001b[0;31m# Import from utils.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthird\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeep3dRec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_lm3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model.third.Deep3dRec.utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%cd /content/HeadSwap\n",
        "!pip install face-alignment\n",
        "!pip install onnxruntime\n",
        "import sys\n",
        "sys.path.append('./model/third/Deep3dRec')\n",
        "sys.path.append('./model/third')\n",
        "from model.AlignModule.generator import FaceGenerator\n",
        "from model.BlendModule.generator import Generator as Decoder\n",
        "from model.AlignModule.config import Params as AlignParams\n",
        "from model.BlendModule.config import Params as BlendParams\n",
        "from model.third.faceParsing.model import BiSeNet\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pdb\n",
        "from process.process_func import Process\n",
        "from process.process_utils import *\n",
        "import os\n",
        "import onnxruntime as ort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0ymbJWEq-edY"
      },
      "outputs": [],
      "source": [
        "class Infer(Process):\n",
        "    def __init__(self,align_path,blend_path,parsing_path,params_path,bfm_folder):\n",
        "        Process.__init__(self,params_path,bfm_folder)\n",
        "        align_params = AlignParams()\n",
        "        blend_params = BlendParams()\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "\n",
        "        self.parsing = BiSeNet(n_classes=19).to(self.device)\n",
        "\n",
        "        self.netG = FaceGenerator(align_params).to(self.device)\n",
        "        self.decoder = Decoder(blend_params).to(self.device)\n",
        "\n",
        "        self.loadModel(align_path,blend_path,parsing_path)\n",
        "        self.eval_model(self.netG,self.decoder,self.parsing)\n",
        "\n",
        "\n",
        "        self.ort_session_sr = ort.InferenceSession('./pretrained_models/sr_cf.onnx', providers=['CPUExecutionProvider'])\n",
        "\n",
        "    def run(self,src_img_path_list,tgt_img_path_list,save_base,crop_align=False,cat=False):\n",
        "        os.makedirs(save_base,exist_ok=True)\n",
        "        i = 0\n",
        "        for src_img_path,tgt_img_path in zip(src_img_path_list,tgt_img_path_list):\n",
        "            gen = self.run_single(src_img_path,tgt_img_path,crop_align=crop_align,cat=cat)\n",
        "            img_name = os.path.splitext(os.path.basename(src_img_path))[0]+'-' + \\\n",
        "                        os.path.splitext(os.path.basename(tgt_img_path))[0]+'.png'\n",
        "            cv2.imwrite(os.path.join(save_base,img_name),gen)\n",
        "            print('\\rhave done %04d'%i,end='',flush=True)\n",
        "            i += 1\n",
        "        print()\n",
        "    def run_single(self,src_img_path,tgt_img_path,crop_align=False,cat=False):\n",
        "\n",
        "        tgt_img = cv2.imread(tgt_img_path)\n",
        "        tgt_align = tgt_img.copy()\n",
        "\n",
        "        tgt_align,info = self.preprocess_align(tgt_img)\n",
        "        if tgt_align is None:\n",
        "            return None\n",
        "\n",
        "        src_img = cv2.imread(src_img_path)\n",
        "        src_align = src_img\n",
        "        if crop_align:\n",
        "            src_align,_ = self.preprocess_align(src_img,top_scale=0.55)\n",
        "\n",
        "        src_inp = self.preprocess(src_align)\n",
        "        tgt_inp = self.preprocess(tgt_align)\n",
        "\n",
        "        tgt_params = self.get_params(cv2.resize(tgt_align,(256,256)),\n",
        "                                info['rotated_lmk']/2.0).unsqueeze(0)\n",
        "\n",
        "        gen = self.forward(src_inp,tgt_inp,tgt_params)\n",
        "\n",
        "        gen = self.postprocess(gen[0])\n",
        "        gen = self.run_sr(gen)\n",
        "        mask = self.mask\n",
        "        final = gen\n",
        "        # gen = color_transfer2(tgt_align,gen)\n",
        "\n",
        "        RotateMatrix = info['im'][:2]\n",
        "        mask = info['mask'][...,0]\n",
        "\n",
        "        rotate_gen = cv2.warpAffine(gen, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0]))\n",
        "        mask = cv2.warpAffine(mask, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0])) * 1.0\n",
        "\n",
        "        # ori_mask = mask.copy()\n",
        "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(17, 17))\n",
        "        # mask = cv2.dilate(mask*1.0,kernel2)\n",
        "        mask = cv2.erode(mask*1.0,kernel2)\n",
        "        # mask = cv2.GaussianBlur(mask*255.0, (21, 21), 0) / 255.0\n",
        "        mask = cv2.blur(mask*1.0, (15, 15), 0) / 255.0\n",
        "        mask = np.clip(mask,0,1.0)[:,:,np.newaxis]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "        final = rotate_gen * mask + tgt_img * (1-mask)\n",
        "\n",
        "        if cat:\n",
        "            final = np.concatenate([tgt_img,final],1)\n",
        "            final[-256:,:256] = cv2.resize(src_align,(256,256))\n",
        "\n",
        "        return final\n",
        "\n",
        "    def forward(self,xs,xt,params):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # xg = self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "            #                 F.adaptive_avg_pool2d(xt,256),\n",
        "            #                 params)['fake_image']\n",
        "            xg = F.adaptive_avg_pool2d(self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "                            F.adaptive_avg_pool2d(xt,256),\n",
        "                            params)['fake_image'],512)\n",
        "\n",
        "\n",
        "            M_a = self.parsing(self.preprocess_parsing(xg))\n",
        "\n",
        "            M_t = self.parsing(self.preprocess_parsing(xt))\n",
        "\n",
        "            M_a = self.postprocess_parsing(M_a)\n",
        "            M_t = self.postprocess_parsing(M_t)\n",
        "            # xg[M_a.repeat(1,3,1,1)==0] = -0.5\n",
        "            # xg[M_a.repeat(1,3,1,1)==16] = 0.6\n",
        "            xg_gray = TF.rgb_to_grayscale(xg,num_output_channels=1)\n",
        "            fake = self.decoder(xg,xg_gray,xt,M_a,M_t,xt,train=False)\n",
        "\n",
        "\n",
        "            gen_mask = self.parsing(self.preprocess_parsing(fake))\n",
        "            gen_mask = self.postprocess_parsing(gen_mask)\n",
        "            gen_mask = gen_mask[0][0].cpu().numpy()\n",
        "            mask_t = M_t[0][0].cpu().numpy()\n",
        "            mask = np.zeros_like(gen_mask)\n",
        "            for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18]:\n",
        "                mask[gen_mask==i] = 1.0\n",
        "                mask[mask_t==i] = 1.0\n",
        "\n",
        "            self.mask = mask\n",
        "        return fake\n",
        "\n",
        "    def run_sr(self,input_np):\n",
        "        input_np = cv2.cvtColor(input_np, cv2.COLOR_BGR2RGB)\n",
        "        # prepare data\n",
        "        input_np = input_np.transpose((2,0,1))\n",
        "        input_np = np.array(input_np[np.newaxis, :])\n",
        "        outputs_onnx = self.ort_session_sr.run(None, {'input_image':input_np.astype(np.uint8)})\n",
        "\n",
        "        out_put_onnx = outputs_onnx[0]\n",
        "        outimg = out_put_onnx[0,...].transpose(1,2,0)\n",
        "        outimg = cv2.cvtColor(outimg, cv2.COLOR_BGR2RGB)\n",
        "        return outimg\n",
        "\n",
        "\n",
        "    def loadModel(self,align_path,blend_path,parsing_path):\n",
        "        ckpt = torch.load(align_path, map_location=lambda storage, loc: storage)\n",
        "        # self.netG.load_state_dict(ckpt['G'])\n",
        "        self.netG.load_state_dict(ckpt['net_G_ema'])\n",
        "\n",
        "        ckpt = torch.load(blend_path, map_location=lambda storage, loc: storage)\n",
        "        self.decoder.load_state_dict(ckpt['G'],strict=False)\n",
        "\n",
        "        self.parsing.load_state_dict(torch.load(parsing_path))\n",
        "\n",
        "\n",
        "    def eval_model(self,*args):\n",
        "        for arg in args:\n",
        "            arg.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlJUASSZZD2H"
      },
      "source": [
        "## model init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kkagbZIP_ZAQ",
        "outputId": "345b9c9c-8c4c-4143-ff10-f78aa76cb4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/HeadSwap/process/process_func.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.ParamsModel.load_state_dict(torch.load(params_path)['net_recon'])\n",
            "<ipython-input-14-267e6b1e17d7>:132: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(align_path, map_location=lambda storage, loc: storage)\n",
            "<ipython-input-14-267e6b1e17d7>:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(blend_path, map_location=lambda storage, loc: storage)\n",
            "<ipython-input-14-267e6b1e17d7>:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.parsing.load_state_dict(torch.load(parsing_path))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Infer(\n",
        "            # 'checkpoint/Aligner/058-00008100.pth',\n",
        "            'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt',\n",
        "            'pretrained_models/Blender-401-00012900.pth',\n",
        "            'pretrained_models/parsing.pth',\n",
        "            'pretrained_models/epoch_20.pth',\n",
        "            'pretrained_models/BFM')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDkXm6S3aTRT"
      },
      "source": [
        "## upload image\n",
        "up_model = 1 -> use upload image\n",
        "up_model = 0 -> use defalut image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Lcuht7vhaVb_",
        "outputId": "0b12d371-dace-4535-b0c3-20d73d538a15"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-aab9f3569c7c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_ALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en_US.UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0muploaded_imgs_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'assets'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded_imgs_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded_imgs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# uploaded_img_name = list(uploaded_img.keys())[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import shutil\n",
        "import os.path as osp\n",
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
        "uploaded_imgs_path = 'assets'\n",
        "if not osp.exists(uploaded_imgs_path) : os.makedirs(uploaded_imgs_path)\n",
        "# uploaded_img_name = list(uploaded_img.keys())[0]\n",
        "def upload_img():\n",
        "  uploaded_img = files.upload()\n",
        "  uploaded_img_name = list(uploaded_img.keys())[0] # Changed uploadded_img_name to uploaded_img_name\n",
        "  uploaded_img_path = os.path.join(os.getcwd(), uploaded_img_name)\n",
        "\n",
        "  base_name, ext = os.path.splitext(uploaded_img_name) # Changed uploadded_img_name to uploaded_img_name\n",
        "  i = 0\n",
        "  while os.path.exists(os.path.join(uploaded_imgs_path, uploaded_img_name)): # Changed uploadded_img_name to uploaded_img_name\n",
        "    i += 1\n",
        "    uploaded_img_name = f\"{base_name}_{i}{ext}\" # Changed uploadded_img_name to uploaded_img_name\n",
        "  # !mv \"{uploadded_img_name}\" \"{uploaded_imgs_path}\"\n",
        "  shutil.move(uploaded_img_name, uploaded_imgs_path)\n",
        "  print(f\"move file {uploaded_img_name} to {uploaded_imgs_path} \")\n",
        "  return os.path.join(uploaded_imgs_path,uploaded_img_name)\n",
        "  # print(uploaded_img.keys())\n",
        "  # for fn in uploaded_img.keys():\n",
        "  #   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "  #       name=fn, length=len(uploaded_img[fn])))\n",
        "up_mode = \"1\" #@param [0, 1]\n",
        "if up_mode:\n",
        "  src = upload_img()\n",
        "  tgt = upload_img()\n",
        "else:\n",
        "  src = './assets/5.jpg'\n",
        "  tgt = 'assets/fe54875c-2cf0-4147-b08a-80552a9f46be.jpg'\n",
        "\n",
        "src_img = cv2.imread(src)\n",
        "cv2_imshow(src_img)\n",
        "tgt_img = cv2.imread(tgt)\n",
        "cv2_imshow(tgt_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUtPyqriZIwu"
      },
      "source": [
        "## run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWPDTpQ_BkcJ"
      },
      "outputs": [],
      "source": [
        "oup = model.run_single(src,tgt,crop_align=True,cat=True)\n",
        "cv2_imshow(oup)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}